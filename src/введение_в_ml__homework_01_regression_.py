# -*- coding: utf-8 -*-

#### small fix
"""Введение в ML_"Homework_01_regression"

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NUVtqNwd56a8HmGGPQ59OXi70hW4dQ9u



# Домашнее задание 1. Регрессия



В этом домашнем задании вам будет необходимо обучить модель регрессии для предсказания стоимости автомобилей (10 основных баллов + 2.5 бонусных)

> Оценка за домашнее задание = $min(\text{ваш балл}, 12.5)$

## Общая информация

__Внимание!__  

* Домашнее задание выполняется самостоятельно
* Не допускается помощь в решении домашнего задания от однокурсников или третьих лиц. «Похожие» решения считаются плагиатом, и все задействованные студенты — в том числе и те, у кого списали, — не могут получить за него больше 0 баллов
* Использование в решении домашнего задания генеративных моделей (ChatGPT и так далее) за рамками справочной и образовательной информации для генерации кода задания — считается плагиатом, и такое домашнее задание оценивается в 0 баллов

**Примечание**

В каждой части оцениваются как код, **так и ответы на вопросы.**

Если нет одного и/или другого, то часть баллов за соответствующее задание снимается.

## Импорт библиотек, установка констант
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import random
import seaborn as sns

CARS_TRAIN = 'https://github.com/evgpat/datasets/raw/refs/heads/main/cars_train.csv'
CARS_TEST = 'https://github.com/evgpat/datasets/raw/refs/heads/main/cars_test.csv'

RANDOM_STATE = 42

random.seed(RANDOM_STATE)
np.random.seed(RANDOM_STATE)

"""## Задание 0

Для чего фиксируем сиды в ноутбуке?

Фиксированный сид нужен, чтобы можно было воспроизвести результаты исследований точь-в-точь, т.к. при запуске кода с фикс. сидом мы будем генерировать те же случайные данные.

42 - дефолтный сид

## Часть 1 | EDA

Первая часть состоит из классических шагов EDA:

- Базовый EDA и обработка признаков (3 балла)
- Визуализации признаков и их анализ (1 балл+0.5)

Всего можно набрать 4 основных балла и 0.5 бонусных.

В следующих частях, вы увидите бонусные задания. Бонусные задания выделены как **Дополнительное задание/Бонус**. Вы можете выполнять их, чтобы в случае ошибок в основных задачах всё равно набрать за работу максимум. Кроме того, дополнительные задания позволяют вам углубить знания.

Призываем активно использовать их!

## **Простейший EDA и обработка признаков (3 балла)**
"""

df_train = pd.read_csv(CARS_TRAIN)
df_test = pd.read_csv(CARS_TEST)

print("Train data shape:", df_train.shape)
print("Test data shape: ", df_test.shape)

"""### **Задание 1.(0.5 балла)**
Выполните операции, направленные на базовое исследование данных:

- [ ] Посмотрите, есть ли в датасете пропуски. Выведите названия колонок, для которых есть пропущенные значения
- [ ] Посмотрите, есть ли в данных явные дубликаты
- [ ] Постройте дашборд в одну строку, используя [ydata-profilling](https://github.com/ydataai/ydata-profiling)
- [ ] Опишите базовые выводы (какие — выберите сами), используя дашборд
"""

df_train.info()

# Пропуски
df_train.isnull().sum()

# Дубликаты явные
# общее число строк дублей, включая все копии
df_train.duplicated().sum()

# Дашборд
!pip install ydata-profiling

from ydata_profiling import ProfileReport
profile = ProfileReport(df_train, title="cars_train dataset report")
# profile.to_file("your_report.html")
profile.to_notebook_iframe()

# Базовые выводы по дашборду

"""На основании дашборда можно сделать следующие выводы:
*   Общее число строк в дублирующихся группах: 493 (7%)
*   Есть незначительные (до 5%) пропущенные значения (2.8–2.9%) в колонках
  *   mileage (202)
  *   engine (202)
  *   max_power (196)
  *   torque (203)
  * seats (202)

* Низкая уникальность значений данных у колонок, которые можно закодировать
  * fuel — 4 уникальных значения
  * seller_type — 3 уникальных значения
  * transmission — 2 уникальных значения
* Высокий дисбаланс в seller_type, т.к. значения в колонке распределены неравномерно
  * Individual — 5826 авто (преобладает более, чем на 80%)
  * Dealer — 967 авто
  * Trustmark Dealer — 206 авто
* Высокая корреляция для
  * km_driven и year	(например, чем новее машина, т.е. больше год выпуска, тем меньше у нее пробег, и наоборот)
  * selling_price и transmission (например, автоматическая коробка передач стоит дороже, т.е. цена выше)
* Есть выбросы в selling_price
  * Maximum	10000000 (10млн)
  * Mean	639515.2 (около 640тыс)

### **Задание 2 (0.4 балла)**
Проанализируйте статистики датасета.

**Ваша задача:**
- [ ] Посчитайте основные статистики по числовым столбцам для трейна и теста
- [ ] Посчитайте основные статистики по категориальным столбцам для трейна и теста
- [ ] Сравните среднее и медиану внутри `train`, внутри `test` и между собой. О чём могут говорить результаты?

**Подсказка:**

Используте ``.describe()`` с нужным(и) аргументом(-ами).
"""

# Статистика по числовым столбцам для трейна
df_train.describe()

# Статистика по числовым столбцам для теста
df_test.describe()

# Статистика по категориальным столбцам для трейна
df_train.describe(include=['O'])

# Статистика по категориальным столбцам для тетса
df_test.describe(include=['O'])

# Сравнение среднего и медианы внутри train
num_cols = df_train.select_dtypes(include=['int64', 'float64']).columns
df_train[num_cols].agg(['mean', 'median'])

# Сравнение среднего и медианы внутри test
num_cols = df_test.select_dtypes(include=['int64', 'float64']).columns
df_test[num_cols].agg(['mean', 'median'])

# Сравнение среднего и медианы между train и test. Результаты

"""1.   Набор train
  * У selling_price среднее значение (639515) выше медианы (450000). Значит, есть в выборке автомобили с высокой ценой
  * В km_driven есть разница между средним (69585) и медианой (60000), что говорит о наличии автомобилей с большим пробегом
2.   Набор test
  * У selling_price среднее значение (617901) выше медианы (434999), структура похожа на train набор
  * В km_driven среднее значение (71393) выше медианы (61500), что также говорит о наличии автомобилей с большим пробегом
3.   Между наборами train и test
  * В year распределение близко к нормальному, медиана ≈ среднему, средний год 2013-2015гг. Год выпуска почти идентичен
  * В seats распределение близко к нормальному, медиана ≈ среднему, у большиснтва автомобилей 5 мест
  * В test наборе selling_price ниже. Возможная причина - отсутствие в тестовом наборе дорогостоящих машин
  * В test наборе km_driven выше. Возможная причина - в тестовом наборе больше б\у автомобилей, нежели в train

### **Задание 3 (0.5 балла)**

- [ ] Посмотрите, есть ли в трейне объекты с одинаковым признаковым описанием (целевую переменную следует исключить). Если есть, то сколько?
- [ ] Отобразите такие объекты
- [ ] Удалите повторяющиеся строки. Если при одинаковом признаковом описании цены на автомобили отличаются, то оставьте первую строку по этому автомобилю
- [ ]  Обновите индексы строк таким образом, чтобы они шли от 0 без пропусков
"""

#  Поиск количества объектов с одинаковым признаковым описанием , исключая целевую переменную (selling_price). Вывод результата
print(f"Найдено дубликатов: {df_train.drop(columns=['selling_price']).duplicated().sum()}")

# Удаление дубликатов, оставляя первую строку
# Изменения происходят в нашем трейне
df_train = df_train.drop_duplicates(subset=df_train.columns.difference(['selling_price']), keep='first')

# Сброс индексов
df_train = df_train.reset_index(drop=True)

assert df_train.shape == (5840, 13)

# Просмотр первых строк после очистки дубликатов
df_train.head()

df_train.info()

"""### **Задание 4 (0.7 балла)**

Вы могли заметить, что с признаками ``mileage, engine, max_power и torque`` всё не очень хорошо. Они распознаются как строки (можно убедиться в этом, вызвав `data.dtypes`). Однако эти переменные не являются категориальными — они — числа. Соответственно, нужно привести их к числовому виду.

**Задача :**
* [ ] Уберите единицы измерения для признаков ``mileage, engine, max_power``.
* [ ] Приведите тип данных к ``float``.
* [ ] Предобработайте признак `torque` — разделите его на два: собственно `torque` и `max_torque_rpm`. Учтите единицы измерения


**Важно**
- Все действия нужно производить над обоими датасетами — `train` и `test`.
"""

# Работа в train

# Удаление единиц измерения для для признаков mileage, engine, max_power и привод к формату данных float

# Смотрим на данные и видим, что числа от единиц измерения разделены пробелом.
# Значит, мы можем воспользовать простой функцией разбиения строки на два (до пробела и после) и оставить нужную численную нам часть.
# Ее же преобразовать в число типа float
df_train['mileage'] = df_train['mileage'].str.split().str[0].astype(float)
df_train['engine'] = df_train['engine'].str.split().str[0].astype(float)
df_train['max_power'] = df_train['max_power'].str.split().str[0].astype(float) # эта часть кода выдала ошибку, поэтому применили регулярное выраж-ие для поиска числовых значений

df_train['max_power'] = df_train['max_power'].str.extract(r'(\d+\.?\d*)').astype(float)

df_train['max_power'].head()

# Предобработка признака torque — разделение его на torque и max_torque_rpm (учесть единицы измерения)
# 1 кгс м = 9,80665 кН м

# Разделение столбца 'torque' на два: сам крутящий момент и макс частоту вращения
split_torque = df_train['torque'].str.split('@', expand=True)

# Столбец 1 - сам КМ (до @). Применяем регуляр. выраж-ие, извлекая только численное знач.
df_train['torque'] = split_torque[0].str.extract(r'(\d+\.*\d*)')[0]

# Столбец 2 - макс частота вращения (после @). Преобразование аналогично + добавлено удаление запятых, т.к. в числах замечены запятые как разделители
df_train['max_torque_rpm'] = split_torque[1].str.extract(r'(\d+,\d*|\d+)')[0].str.replace(',','', regex=True)

# Проверка на наличие кгметров и их конвертация в ньютонометры
# Не учитываем регистр, чтобы найти любую запись кгметров. Не трогаем пропущенные значения во избежание ошибок обработки. То, что конвертировали сразу преобразовали в float
if_kgm = df_train['torque'].str.contains('kgm', case=False, na=False)
df_train.loc[if_kgm, 'torque'] = df_train.loc[if_kgm, 'torque'].astype(float) * 9.80665

# Преобразование в числовой формат
df_train['torque'] = df_train['torque'].astype(float)
df_train['max_torque_rpm'] = df_train['max_torque_rpm'].astype(float)

df_train.dtypes

df_train[['mileage', 'engine', 'max_power', 'torque', 'max_torque_rpm']].head()

# Работа в test (всё то же самое, что для трейна)
df_test['mileage'] = df_test['mileage'].str.split().str[0].astype(float)
df_test['engine'] = df_test['engine'].str.split().str[0].astype(float)
df_test['max_power'] = df_test['max_power'].str.extract(r'(\d+\.?\d*)').astype(float)

# Предобработка признака torque — разделение его на torque и max_torque_rpm (учесть единицы измерения)
split_torque = df_test['torque'].str.split('@', expand=True)
df_test['torque'] = split_torque[0].str.extract(r'(\d+\.*\d*)')[0]
df_test['max_torque_rpm'] = split_torque[1].str.extract(r'(\d+,\d*|\d+)')[0].str.replace(',','', regex=True)
if_kgm = df_test['torque'].str.contains('kgm', case=False, na=False)
df_test.loc[if_kgm, 'torque'] = df_test.loc[if_kgm, 'torque'].astype(float) * 9.80665
df_test['torque'] = df_test['torque'].astype(float)
df_test['max_torque_rpm'] = df_test['max_torque_rpm'].astype(float)

df_test[['mileage', 'engine', 'max_power', 'torque', 'max_torque_rpm']].head()

df_test.dtypes

"""### **Задание 5 (0.4 балла)**

На первом шаге мы обнаружили пропуски. Давайте избавимся от них.

**Задание:**
- [ ] Заполните пропуски в столбцах медианами. Убедитесь, что после заполнения пропусков не осталось.
- [ ] Почему стоит применять именно медиану. Могли ли мы применить среднее? Обоснуйте свое рассуждение.
- [ ] Как правильно считать медиану для заполнения? Выберите верное утверждение:
 - По тестовым свою, по тренировочным — свою
 - По тренировочным данным для `train` и `test`

Стоит применять медиану, потмоу что она устойчива к выбросам. В наших данных selling_price и km_driven имеют разброс в данных. Плюс, в данных есть технические характеристики автомобилей, например, мощность двигателя, которые могут быть распределены неравномерно. И в этом случае медиана лучше отразит "центр" данных.

Меадину правильно считать по тренировочным данным для train и test, чтобы тестовый набор данных оставался максимально нетронутым, а пропуски были заполнены статистикой на основе обучающих данных. Плюс, по трейну мы не допуст учетки информации.
"""

df_train.isnull().sum()

df_test.isnull().sum()

# Заполнение медианы в трейн и тесте по трейну
for col in ['mileage', 'engine', 'max_power', 'torque', 'seats', 'max_torque_rpm']:
    df_train[col].fillna(df_train[col].median(), inplace=True)
    df_test[col].fillna(df_train[col].median(), inplace=True)

df_train.isnull().sum()

df_test.isnull().sum()

"""### **Задание 6 (0.3 балла)**

Теперь, когда не осталось пропусков, давайте преобразуем столбцы к более подходящим типам. А именно столбцы ``engnine`` и ``seats`` к приведем к `int`.

- [ ] Осуществите приведение столбцов к необходимому типу.
- [ ] Ответье на вопрос — почему (хоть мы этого и не делаем) ``seats``, возможно рассмотреть как категориальную переменную?
"""

df_train['engine'] = df_train['engine'].astype(int)
df_train['seats'] = df_train['seats'].astype(int)
df_test['engine'] = df_test['engine'].astype(int)
df_test['seats'] = df_test['seats'].astype(int)

"""seats - это столбец с ограниченным числом возможных значений и теоретически его можно превратить в категории"""

df_train.dtypes

df_test.dtypes

"""### **Задание 7 (0.2 балла)**

Снова вызовите метод `describe` и проанализируйте статистики.

**Ответьте на вопрос:**
- [ ] Есть ли основания предполагать, что заполнение пропусков свдинуло наши распределения? Могло ли это вообще возникнуть?
"""

df_train.describe()

df_test.describe()

"""В трейн наборе среднее значение немного повысилось для engine, max_power и torque; увеличилось std. Это характеризуется тем, что заполнение пропусков медианными значениями изменило состав данных, разброс около среднего вырос. Данные стали более разнообразными, однако само распределение осталось почти неизменным.


В тестовом наборе torque увеличился.


Таким образом, проставление медианных значений на место пропусков, действительно, повлияло на статистику (например, среднее). Там, где у данных широкий спектр значений (например, мощность) воздействие заполнения пропусков медианой было сильнее выражено.
Однако эти изменения не оказали какого-то сильного негативного влияния на наши наборы.

## **Визуализации и корреляция (1 балл + 0.5)**

Визуализация данных — важный шаг в работе. Визуализировать данные необходимо, например, чтобы:

- Оценить распределения признаков самих по себе (это может натоклнуть вас на мысли о модели, которую можно использовать)
- Сравнить распределения на `train` и `test` — чтобы проверить, насколько информация, на которой вы будете обучаться согласуется с той, на которой модель должна работать
- Оценить есть ли явная связь признаков с целевой переменной

**Важно:**

Если распределения на `train` и `test` не совпадают, это не значит, что нужно перемешивать данные! Более корректно актуализировать задачу и уточнить, а не устарели ли данные `train`. Также полезным может быть собрать новую тестовую выборку, смешав те, что имеются сейчас.

**Если вы будете подгонять распределения, то можете встретиться с переобучением!**

### **Задание 8 (0.5 балла)**

Шаг 1.
- [ ] Воспользуйтесь `pairplot` из библиотеки `seabron`, чтобы визуализировать попарные распределения числовых признаков для `train`
- [ ] По полученному графику ответьте на вопросы:
 - Можно ли предположить на основе распределений связь признаков с целевой переменной?
 - Можно ли предположить на основе распределений выдвинуть гипотезу о корреляциях признаков?

Шаг 2.

- [ ] Постройте `pairplot` по тестовым данным
- [ ] Ответьте на вопрос "Похожими ли оказались совокупности при разделении на трейн и тест?"
"""

# Внесение числовых признаков в переменную
num_features = ['year', 'km_driven', 'mileage', 'engine', 'max_power', 'torque', 'seats', 'max_torque_rpm', 'selling_price']

# Построение графиков для train
plt.figure(figsize=(12, 6))
sns.pairplot(data=df_train[num_features])
plt.show()

# Построение графиков для test
plt.figure(figsize=(12, 6))
sns.pairplot(data=df_test[num_features])
plt.show()

"""Выводы на основании графиков:
* Есть зависимость между годом выпуска автомобиля и его пробегом. Чем ниже year, тем выше km_driven.
* Мощность двигателя (max_power) коррелируется с его объемом (engine). Чем больше объём двигателя, тем выше его мощность
* mileage и engine коррелируются

Связь с целевой переменной:
* положительная корреляция с годом выпуска автомобиля (year): чем старше автомобиль, тем ниже цена
* отрицательная корреляция с пробегом (km_driven): чем выше пробег, тем ниже цена
* кол-во мест (seats): связи почти нет, отсутствует

Сравнение train и test наборов:
* Распределение ключевых признаков (year, km_driven, engine) на графиках визуально похожи в обоих наборах. Наиболее влиюящие на цену признаки - year и km_driven. Таким образом, можешь сделать вывод, что разделение у нас корректное, в целом гистограммы значимых признаков построены схоже.

### **Задание 9 (0.5 балла)**

И так, вы выдвинули гипотезы о наличии связи. Теперь давайте оценим эту связь в числах.

**Задание:**
- [ ] Получите значения коэффициента корреляции Пирсона для тренировочного набора данных при помощи `pd.corr()`
- [ ] По полученным корреляциям постройте тепловую карту (`heatmap` из бибилотеки seaborn)
"""

num_col = df_train.select_dtypes(include=['number'])
num_col.corr(method='pearson')

# Фильрация по числовых столбцам
num_col = df_train.select_dtypes(include=['number'])
# Вычисление коэффициента корреляции по Пирсону
corr_matrix = num_col.corr(method='pearson')

# Тепловая карта
plt.figure(figsize=(10, 8))
sns.heatmap(corr_matrix, annot=True, cmap="coolwarm", fmt=".2f")
plt.show()

"""- [ ] Ответьте на вопросы:
 - Какие 2 признака наименее скоррелированы между собой?
 - Между какими наблюдается довольно сильная положительная линейная зависимость?
 - Правильно ли, опираясь на данные, утверждать, что чем меньше год, тем, скорее всего, больше километров проехала машина к дате продажи?

* Наименее скоррелированы между собой признаки year и engine
 * Самая большая положительная корреляция между признаками max_power и torque (≈ 0,74)
 * В корреляционной тепловой карте мы видим, что корреляция между year и km_driven ≈ -0,37. Т.к. значение отрицательное, делаем вывод: чем меньше год выпуска, тем больше км данных автомобиль проехал у моменту продажи. А, значит, наше утверждение верно.

### **Дополнительные визуализации (бонус 0.5 балла)**

Если вам кажется, что мы не попросили вас нарисовать какие-то очень важные зависимости, нарисуйте их и поясните.
"""

# График распределения года выпуска
sns.histplot(df_train['year'], kde=True)
# с 2011 по 2018 гг выпуска автомобили в выборке преобладают

# График отображения связи целевой переменной с годом выпуска
sns.scatterplot(data=df_train, x='year', y='selling_price')
# Еще раз подтверждает, что есть зависимость: чем новее автомобиль (больше год выпуска), тем выше цена

# График сравнения распределения года выпуска в трейн и тест выборках
plt.figure(figsize=(10,4))
plt.subplot(121)
sns.histplot(df_train['year'], color='blue', label='Train')
plt.subplot(121)
sns.histplot(df_test['year'], color='green', label='Test')
plt.show()

# График по отображению связей с ключевыми числовыми признаками
sns.pairplot(
    data=df_train,
    vars=['year', 'km_driven', 'max_power', 'selling_price'],
    corner=True, # чтобы сэкономить пространство
    plot_kws={'alpha': 0.5} # уменьшила плотность точек для лучшего визуала
)

"""# **Часть 2 (4 балла) | Модель только на вещественных признаках**

В этой части вам предстоит обучить модель только на вещественных признаках. Почему только на них?

Чем больше признаковое пространство — чем сложнее модель. А чем модель проще — тем лучше для скорости работы и интерпретации признаков.

За задания этой части вы можете набрать 4 основных баллов;

### **Задание 10 (0.3 балла)**

Создайте копии тренировочного и тестового датафреймов, в которых останутся только вещественные признаки (то есть категориальные столбцы (все, кроме seats) необходимо удалить).

В переменные y_train и y_test запишите значения целевых переменных.
"""

# Создание копий ДФ
X_train = df_train.copy()
X_test = df_test.copy()

df_train.describe(include=['O'])

y_train = X_train.pop('selling_price')
X_train = X_train.drop(columns=['name', 'fuel', 'seller_type', 'transmission', 'owner'])

assert X_train.shape == (5840, 8)

y_test = X_test.pop('selling_price')
X_test = X_test.drop(columns=['name', 'fuel', 'seller_type', 'transmission', 'owner'])

assert X_test.shape == (1000, 8)

"""### **Задание 11 (1 балл)**

Построим нашу первую модель!
- [ ] Найдите паремтры модели с помощью аналитического решения уравнения $\theta = (X^T X)^{-1} X^T y$. *Параметры ищите только по датасету `train`.* Не забудьте добавить столбец из единиц в качестве свободного члена!
- [ ] Посчтитайте $R^2$ и $MSE$ для трейна и для теста (с помощью готовых решений из sklearn).
- [ ] Сделайте выводы по значениям метрик качества.

**Примечание:**

Здесь и далее $R^2$ и $MSE$ для трейна и для теста выводите везде, где требуется обучать модели, даже если в явном виде этого не просят. Иначе непонятно, как понять, насколько успешны наши эксперименты.
"""

from sklearn.metrics import r2_score, mean_squared_error as MSE

# Добавление столбца единиц для свободного члена (смещения)
# Добавление массива только из единиц размеров = кол-ву записей в наборе. Объед-ие этого столбца (располагаем слева) с нашими данными
X_train_b = np.c_[np.ones(len(X_train)), X_train]
X_test_b = np.c_[np.ones(len(X_test)), X_test]

# Вычисление коэффициентов линейной регрессии методом наименьших квадратов
# Формула: θ = (X^T * X)^(-1) * X^T * y
theta_best = np.linalg.inv(X_train_b.T @ X_train_b) @ X_train_b.T @ y_train.values.reshape(-1, 1)

# Вывод найденных коэффициентов
print("Оцененные коэффициенты (θ):", theta_best.ravel())

"""* Свободный член = -7.72505956e+07
* year = 3.83353993e+04 (доп год выпуска автомобиля увеличивает его стоимость. Чем новее автомобиль, тем он дороже)
* km_driven = -8.06255917e-01 (доп пробег снижает стоимость автомобиля)
* mileage = -1.58211770e+03 (увеличение расхода топлива (?) уменьшает стоимость автомобиля)
* engine = 4.43772466e+01 (увеличение мощности автомобиля увеличивает его стоимость)
* max_power = 9.21288999e+03 (мощность двигателя автомобиля увеличивает его стоимость)
* torque = 5.37905504e+02 (КМ автомобиля увеличивает его стоимость)
* seats = -3.43035645e+04 (бОльшее кол-во мест снижает стоимость автомобиля)
* max_torque_rpm = -3.61003271e+01 (доп оборот двигателя автомобиля понижает его стомость)
"""

# Подсчет предсказаний
y_predict_train = X_train_b @ theta_best
y_predict_test = X_test_b @ theta_best

# Подсчет метрик модели
print("Метрики на train данных:")
print(f"R2: {r2_score(y_train, y_predict_train)}")
print(f"MSE: {MSE(y_train, y_predict_train)}")

print("Метрики на test данных:")
print(f"R2: {r2_score(y_test, y_predict_test)}")
print(f"MSE: {MSE(y_test, y_predict_test)}")

"""Выводы:
* Качество модели можно назвать умеренным,т.к. R^2 в обоих наборах ≈ 0,6. Около 40% изменчивости цен на автомобили модель не учитывает. Из плюсов отметим, что R^2 почти одинакова в обоих наборах, а, значит, нет переобучения, модель отрабатывает на обоих наборах одинаково.
* Среднеквадратичная ошибка выдает большие отклонения. Извлекая корень, получаем данные порядка 337тыс. для трейна и 480тыс. для теста при учете средней цены 550тыс. для наборов. Это очень высокие ошибки в сопоставлении со средней ценой:
  * ≈ 64% для трейна
  * ≈ 86% для теста

Таким образом, можно назвать текущую модель почти неинформативными. Модель требует доработки
"""

# Средняя цена
y_train.mean()

y_test.mean()

"""### **Задание 12. (0.3 балла)**
Теперь сравним результаты с готовым решением из библиотеки sklearn.

- [ ] Обучите классическую линейную регрессию с дефолтными параметрами c помощью LinearRegression.
- [ ] Посчтитайте $R^2$ и $MSE$ для трейна и для теста.

"""

from sklearn.linear_model import LinearRegression
model = LinearRegression()
model.fit(X_train, y_train)

y_pred_train = model.predict(X_train)
print("Метрики на train данных:")
print(f"MSE: {MSE(y_train, y_pred_train)}")
print(f"R2: {r2_score(y_train, y_pred_train)}")

y_pred_test = model.predict(X_test)
print("Метрики на test данных:")
print(f"MSE: {MSE(y_test, y_pred_test)}")
print(f"R2: {r2_score(y_test, y_pred_test)}")

"""* R^2 изменился незначительно по сравнению с предыдущими метриками.
* По похожим метрикам между трейн и тестом можно также судить об отсутствии существенного переобучении модели
* Плюс, R^2 ≈ 0,6, как и в предыдущих метриках.
* Квадратичная ошибка всё также высокая

### **Задание 13 (0.2 балла)**

Всегда есть место совершенству. Поэтому давайте попробуем улучшить модель. При помощи стандартизации признаков.

- [ ] Стандартизируйте признаки в тренировочных и тестовых данных. Стандартизатор **обучайте только на `train`**.
"""

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
# Обучение только на трейн
X_train_scaled = scaler.fit_transform(X_train)
# Для теста нет переобучения
X_test_scaled = scaler.transform(X_test)
model_std = LinearRegression()
model_std.fit(X_train_scaled, y_train)
# Предсказание
y_pred_train_std = model_std.predict(X_train_scaled)
y_pred_test_std = model_std.predict(X_test_scaled)

print("Метрики на train данных:")
print(f"MSE: {MSE(y_train, y_pred_train)}")
print(f"R2: {r2_score(y_train, y_pred_train)}")

print("Метрики на test данных:")
print(f"MSE: {MSE(y_test, y_pred_test)}")
print(f"R2: {r2_score(y_test, y_pred_test)}")

"""Теперь MSE на тест данных выше, чем на трейне. Можем говорить о некоторой степени переобучения

### **Задание 14 (0.2 балла)**

Хотя стандартизация не помогла сильно прибавить в качестве она открыла возможность интерпретировать важность признаков в модели. Правило интерпретации такое:

Чем больше коэффициент $\beta_i$ по модулю, тем важнее признак.

**Ответьте на вопрос:**

- [ ] Какой признак оказался наиболее информативным в предсказании цены?
"""

coef = model_std.coef_
print(coef) # просто смотрим коэф-ты по всем признакам
# Определение наиболее информативного признака
max_coef_idx = abs(coef).argmax()
feature_n = X_train.columns[max_coef_idx]

# Вывод результата
print(f"Наиболее информативный признак: {feature_n}")
print(f"Коэффициент признака: {coef[max_coef_idx]}")

"""Итого, вывод показал, что признак max_power больше всего влияет на цену

### **Задание 15 (0.3 балла)**

Попробуем улучшить нашу модель с помощью применения регуляризации. Для этого воспльзуемся `Lasso` регрессией.  Кроме того, попробуйте использовать её теоретическое свойство отбора признаков, за счет зануления незначимых коэффициентов.

**Задание:**

- [ ] Обучите Lasso регрессию на тренировочном наборе данных с нормализованными признаками. Оцените её качество
- [ ] Проверьте, занулила ли L1-регуляризация с параметрами по умолчанию какие-нибудь веса? Предположите почему.
"""

from sklearn.linear_model import Lasso
lasso = Lasso(alpha=1.0)  # парамер по умолчанию
lasso.fit(X_train_scaled, y_train)

# Счет зануленных коэффициентов
zero_sum = np.sum(lasso.coef_ == 0)
print(f"Кол-во зануленных коэффициентов: {zero_sum}")

"""Модель показала, что нет зануленных признаков, все признаны полезными"""

# Вывод коэффициентов
for feature, coef in zip(X_train.columns, lasso.coef_):
   print(f"{feature}: {coef}")

"""Итого, регуляризация не снизила значимость ни одного признака до 0, как мы видели выше, однако наиболее влияющие признаки
* положительный коэффициент: year, max_power
* отрицательный коэффициент: km_driven
"""

y_pred_train_lasso = lasso.predict(X_train_scaled)

print("Метрики на train данных:")
print(f"RMSE: {MSE(y_train, y_pred_train_lasso)**0.5}")
print(f"R2: {r2_score(y_train, y_pred_train_lasso)}")

"""### **Задание 16. Реализация градиентного бустинга (1.2 балла)**

Теперь попробуем применить метод градиентного спуска для решения уравнения линейной регресии. Вам предстоит дополнить код так, чтобы получился алгоритм полного градиентного спуска. Затем, с помощью полученной функции предстоит снова обучить модель на `train` данных и сделать два предсказания: для `train` и `test`.


**Ваша задача :**

- [ ] Добавить столбец из единиц к своему датасету
- [ ] Дополнить функцию градиентного спуска
- [ ] Применить полученную функцию к train датасету
- [ ] Сделать предсказания для `train` и `test`. Оценить предсказания с помощью $R^2$ и $MSE$.
"""

# Доработайте: добавьте столбец единиц к X
X_train_b = np.c_[np.ones((len(X_train), 1)), X_train_scaled]
X_test_b = np.c_[np.ones((len(X_test), 1)), X_test_scaled]
# Функция градиентного спуска
def gradient_descent(X, y, learning_rate=0.1, n_iterations=1000):
    """
    Реализация градиентного спуска для линейной регрессии.

    Параметры:
    X - матрица признаков с добавленным единичным столбцом
    y - вектор целевой переменной
    learning_rate - скорость обучения
    n_iterations - количество итераций

    Возвращает:
    theta - оцененные коэффициенты модели
    """
    m, n = X.shape  # Количество примеров (m) и количество признаков (n)
    theta = np.random.randn(n, 1)  # Инициализируйте theta случайными значениями

    for iteration in range(n_iterations):
        gradients = (2/m) * X.T @ (X @ theta - y)  # Рассчитайте градиент функции потерь (MSE) (надо обновить коэф тетты для уменьшения ошибки)
        # Градиент = удвоенное произведение транспонированной матрицы признаков X, умноженной на разность между предсказанными значениями (Xθ) и истинными значениями (y) и делённой на число примеров (m).
        theta -= learning_rate * gradients  # Обновите параметры

        if iteration % 100 == 0:
            mse = ((X @ theta - y)**2).mean()  # Вычислите MSE для отслеживания процесса
            # Предсказание с текущей версией коэффициентов - реальное значение. Полученную разность в квадрат и усредняем по всем примерам
            print(f"Итерация {iteration}: MSE = {mse:.4f}")

    return theta

# Доработайте: вызовите функцию градиентного спуска
theta_gd = gradient_descent(X_train_b, y_train.values.reshape(-1, 1))  # Ваш код здесь
print("Оцененные коэффициенты (градиентный спуск):", theta_gd.ravel())

# Получите новые предсказания для train и test
y_pred_test_grad = X_test_b @ theta_gd  # Вычислите предсказания для test
y_pred_train_grad = X_train_b @ theta_gd  # Вычислите предсказания для train

# Посчитайте RMSE и R2
print("Метрики на train данных:")
print(f"MSE: {MSE(y_train, y_pred_train_grad)}")
print(f"R2: {r2_score(y_train, y_pred_train_grad)}")

print("Метрики на test данных:")
print(f"MSE: {MSE(y_test, y_pred_test_grad)}")
print(f"R2: {r2_score(y_test, y_pred_test_grad)}")

"""### Задание 17 (0.5 балла):

- [ ] Сделайте еще одно обучение модели для готового решения стохастического градиентного спуска из sklearn
- [ ] Оцените результаты с помощью $R^2$ и $MSE$
"""

from sklearn.linear_model import SGDRegressor

# Обучение модели
sgd_model = SGDRegressor(alpha=0.1, random_state=42, max_iter=10000)
sgd_model.fit(X_train_scaled, y_train)

# Вывод коэффициентов
theta_sgd = sgd_model.coef_
print(theta_sgd)

# Предсказания
y_pred_train_sgd = sgd_model.predict(X_train_scaled)
y_pred_test_sgd = sgd_model.predict(X_test_scaled)

print("Метрики на train данных:")
print(f"MSE: {MSE(y_train, y_pred_train_sgd)}")
print(f"R2: {r2_score(y_train, y_pred_train_sgd)}")

print("Метрики на test данных:")
print(f"MSE: {MSE(y_test, y_pred_test_sgd)}")
print(f"R2: {r2_score(y_test, y_pred_test_sgd)}")

"""# **Часть 3 (1 балл) | Добавляем категориальные фичи**

Попробуем для улучшения модели дать ей больше признаков. Добавим категориальные фичи.

За эту часть можно набрать 1 основной балл.

### **Задание 19 (0.2 балла)**

Проанализируйте столбец `name`. Очевидно, что эта переменная является категориальной, однако категорий в ней много.

- [ ] Предобработайте столбец `name`, чтобы избежать его удаления
"""

X_train_cat = df_train.copy()
X_train_cat.shape

(X_train_cat['name'].head())

"""По выводу логично оставить только название бренда для упрощения (только первое слово)"""

X_train_cat['name'] = X_train_cat['name'].str.split().str[0]

assert X_train_cat.shape == (5840, 14)

X_train_cat.describe(include='object')

"""### **Задание 20 (0.2 балла)**

- [ ] Закодируйте категориалльные фичи и ``seats`` методом OneHot-кодирования.
"""

from sklearn.preprocessing import OneHotEncoder # или можно использовать get_dummies из библиотеки pandas
X_train_cat_encoded = pd.get_dummies(X_train_cat, columns=['name', 'fuel', 'seller_type', 'transmission', 'owner', 'seats'], drop_first=True)

X_train_cat_encoded.head()

"""### **Задание 21 (0.2 балла)**

OHE — базовый алгоритм преобразования категориальных признаков, но и с ним нужно быть аккуратными.

**Ответьте на вопросы:**


* Как корректно работать с OHE преобразованием?
* Почему мы удаляем один столбец?
* Пусть из $n$ признаков мы получили $n-1$ столбец, из которых $k < n -1$ оказались не важными по весам модели. Корректно ли их удалить?

1. Как корректно работать с OHE преобразованием?

Следить за количеством создаваемых признаков. Если их много - использовать другой подход. Плюс, обучать на трейн данных, а уже потом применять к тестовым
2. Почему мы удаляем один столбец?

Если у нас есть n-категорий, нам необязательно хранить все n-столбцов для них, т.к. один столбец восстановит инф-ию по отсутсвию единиц в последенц. Поэтому n-1 столбцов помогает избежать дублирования информации
3. Корректно ли удалять столбцы, которые оказались неважными по результатам модели?

Если эти признаки никак не влияют на модель, то после ее обучения - да. В противном случае можно потерять инф-ию

### **Задание 22 (0.4 балла)**
Повторим то, что делали на прошлом шаге для моделей на вещественных признаках, однако теперь с моделью `Ridge`.


**Ваша задача:**
- [ ] Обучите Ridge регрессию на новом датасете
- [ ] Ответье на вопрос: Удалось ли улучшить качество прогнозов?
"""

from sklearn.linear_model import Ridge

ridge = Ridge(alpha=1.0)  # также беру дефолтный параметр
ridge.fit(X_train_scaled, y_train) # беру нормированные данные

y_pred_train_ridge = ridge.predict(X_train_scaled)
y_pred_test_ridge = ridge.predict(X_test_scaled)

print("Метрики на train данных:")
print(f"MSE: {MSE(y_train, y_pred_train_ridge)}")
print(f"R2: {r2_score(y_train, y_pred_train_ridge)}")

print("Метрики на test данных:")
print(f"MSE: {MSE(y_test, y_pred_test_ridge)}")
print(f"R2: {r2_score(y_test, y_pred_test_ridge)}")

"""MSE на обоих наборах увеличилась по сравнению с линейной регрессией и SGD.
Показатели R^2 почти без изменений



